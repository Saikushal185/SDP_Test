{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkinson's Disease Feature-Centric Comparative Study\n",
    "## Results Analysis Notebook\n",
    "\n",
    "This notebook provides interactive exploration of the experiment results from the 2×2 cross-paradigm testing framework.\n",
    "\n",
    "**Components:**\n",
    "- Feature Selection: Classical (Random Forest) vs Quantum-Inspired (QIGA)\n",
    "- Models: XGBoost, MLP (Classical) vs QNN (Quantum-Inspired)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T09:19:33.885120Z",
     "iopub.status.busy": "2026-01-04T09:19:33.885120Z",
     "iopub.status.idle": "2026-01-04T09:19:48.538916Z",
     "shell.execute_reply": "2026-01-04T09:19:48.538916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories:\n",
      "  Results: C:\\Users\\saiku\\OneDrive\\Desktop\\SDP_Test\\parkinson_feature_study\\notebooks\\..\\results\n",
      "  Metrics: C:\\Users\\saiku\\OneDrive\\Desktop\\SDP_Test\\parkinson_feature_study\\notebooks\\..\\results\\metrics\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Results directories\n",
    "RESULTS_DIR = Path('../results')\n",
    "METRICS_DIR = RESULTS_DIR / 'metrics'\n",
    "FIGURES_DIR = RESULTS_DIR / 'figures'\n",
    "FEATURES_DIR = RESULTS_DIR / 'selected_features'\n",
    "\n",
    "print(\"Directories:\")\n",
    "print(f\"  Results: {RESULTS_DIR.absolute()}\")\n",
    "print(f\"  Metrics: {METRICS_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T09:19:48.621408Z",
     "iopub.status.busy": "2026-01-04T09:19:48.621408Z",
     "iopub.status.idle": "2026-01-04T09:19:48.632866Z",
     "shell.execute_reply": "2026-01-04T09:19:48.632866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results not found. Run experiments first: python experiments/run_experiment.py\n"
     ]
    }
   ],
   "source": [
    "# Load cross-validation results\n",
    "try:\n",
    "    cv_results = pd.read_csv(METRICS_DIR / 'cross_validation_results.csv')\n",
    "    agg_results = pd.read_csv(METRICS_DIR / 'aggregated_results.csv')\n",
    "    stats_tests = pd.read_csv(METRICS_DIR / 'statistical_tests.csv')\n",
    "    stability = pd.read_csv(METRICS_DIR / 'feature_stability.csv')\n",
    "    \n",
    "    print(f\"Loaded {len(cv_results)} CV results\")\n",
    "    print(f\"Loaded {len(agg_results)} aggregated results\")\n",
    "    print(f\"Loaded {len(stats_tests)} statistical tests\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Results not found. Run experiments first: python experiments/run_experiment.py\")\n",
    "    cv_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Performance Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T09:19:48.637958Z",
     "iopub.status.busy": "2026-01-04T09:19:48.637958Z",
     "iopub.status.idle": "2026-01-04T09:19:48.643821Z",
     "shell.execute_reply": "2026-01-04T09:19:48.643821Z"
    }
   },
   "outputs": [],
   "source": [
    "if cv_results is not None:\n",
    "    # Display aggregated results\n",
    "    display_cols = ['feature_method', 'model', 'accuracy_mean', 'accuracy_std', \n",
    "                   'f1_mean', 'f1_std', 'roc_auc_mean', 'roc_auc_std']\n",
    "    \n",
    "    print(\"\\nAggregated Performance (Mean ± Std):\")\n",
    "    print(\"=\" * 80)\n",
    "    display(agg_results[display_cols].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T09:19:48.649881Z",
     "iopub.status.busy": "2026-01-04T09:19:48.647870Z",
     "iopub.status.idle": "2026-01-04T09:19:48.660023Z",
     "shell.execute_reply": "2026-01-04T09:19:48.658617Z"
    }
   },
   "outputs": [],
   "source": [
    "if cv_results is not None:\n",
    "    # Create performance comparison heatmaps\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    for ax, fs_method in zip(axes, ['classical', 'quantum_inspired']):\n",
    "        data = agg_results[agg_results['feature_method'] == fs_method]\n",
    "        metrics = ['accuracy_mean', 'precision_mean', 'recall_mean', 'f1_mean', 'roc_auc_mean']\n",
    "        \n",
    "        heatmap_data = data[['model'] + metrics].set_index('model')\n",
    "        heatmap_data.columns = [m.replace('_mean', '') for m in metrics]\n",
    "        \n",
    "        sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "                   vmin=0.5, vmax=1.0, ax=ax)\n",
    "        ax.set_title(f'{fs_method.replace(\"_\", \" \").title()} Features')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / 'performance_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistical Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T09:19:48.664978Z",
     "iopub.status.busy": "2026-01-04T09:19:48.664978Z",
     "iopub.status.idle": "2026-01-04T09:19:48.671594Z",
     "shell.execute_reply": "2026-01-04T09:19:48.670575Z"
    }
   },
   "outputs": [],
   "source": [
    "if cv_results is not None:\n",
    "    print(\"\\nStatistical Tests Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Significant results\n",
    "    significant = stats_tests[stats_tests['significant'] == True]\n",
    "    if len(significant) > 0:\n",
    "        print(f\"\\n{len(significant)} significant differences found (p < 0.05):\")\n",
    "        display(significant[['comparison', 'metric', 'difference', 'p_value']])\n",
    "    else:\n",
    "        print(\"\\nNo statistically significant differences found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Stability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T09:19:48.673615Z",
     "iopub.status.busy": "2026-01-04T09:19:48.673615Z",
     "iopub.status.idle": "2026-01-04T09:19:48.682167Z",
     "shell.execute_reply": "2026-01-04T09:19:48.682167Z"
    }
   },
   "outputs": [],
   "source": [
    "if cv_results is not None:\n",
    "    print(\"\\nFeature Selection Stability:\")\n",
    "    print(\"=\" * 80)\n",
    "    display(stability)\n",
    "    \n",
    "    # Visualize stability\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    stability.plot(x='method', y='jaccard_mean', kind='bar', \n",
    "                  yerr='jaccard_std', ax=ax, legend=False)\n",
    "    ax.set_ylabel('Jaccard Similarity')\n",
    "    ax.set_xlabel('Feature Selection Method')\n",
    "    ax.set_title('Feature Stability Across Folds')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / 'feature_stability.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Box Plots by Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T09:19:48.685331Z",
     "iopub.status.busy": "2026-01-04T09:19:48.685331Z",
     "iopub.status.idle": "2026-01-04T09:19:48.693662Z",
     "shell.execute_reply": "2026-01-04T09:19:48.693662Z"
    }
   },
   "outputs": [],
   "source": [
    "if cv_results is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    for ax, metric in zip(axes, ['accuracy', 'roc_auc']):\n",
    "        sns.boxplot(\n",
    "            data=cv_results, \n",
    "            x='model', \n",
    "            y=metric, \n",
    "            hue='feature_method',\n",
    "            ax=ax\n",
    "        )\n",
    "        ax.set_title(f'{metric.replace(\"_\", \" \").upper()} by Model and Feature Method')\n",
    "        ax.set_ylim(0, 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / 'boxplots.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Overlap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T09:19:48.693662Z",
     "iopub.status.busy": "2026-01-04T09:19:48.693662Z",
     "iopub.status.idle": "2026-01-04T09:19:48.707041Z",
     "shell.execute_reply": "2026-01-04T09:19:48.707041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and analyze selected features\n",
    "if FEATURES_DIR.exists():\n",
    "    classical_features = []\n",
    "    quantum_features = []\n",
    "    \n",
    "    for f in FEATURES_DIR.glob('classical_features_fold_*.csv'):\n",
    "        df = pd.read_csv(f)\n",
    "        classical_features.extend(df['feature_name'].tolist())\n",
    "    \n",
    "    for f in FEATURES_DIR.glob('quantum_inspired_features_fold_*.csv'):\n",
    "        df = pd.read_csv(f)\n",
    "        quantum_features.extend(df['feature_name'].tolist())\n",
    "    \n",
    "    if classical_features and quantum_features:\n",
    "        classical_set = set(classical_features)\n",
    "        quantum_set = set(quantum_features)\n",
    "        \n",
    "        overlap = classical_set & quantum_set\n",
    "        only_classical = classical_set - quantum_set\n",
    "        only_quantum = quantum_set - classical_set\n",
    "        \n",
    "        print(f\"\\nFeature Overlap Analysis:\")\n",
    "        print(f\"  Features unique to Classical: {len(only_classical)}\")\n",
    "        print(f\"  Features unique to Quantum: {len(only_quantum)}\")\n",
    "        print(f\"  Overlapping features: {len(overlap)}\")\n",
    "        \n",
    "        if overlap:\n",
    "            print(f\"\\nTop overlapping features: {list(overlap)[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "1. **Feature Selection Impact**: Compare classical vs quantum-inspired feature selection\n",
    "2. **Model Performance**: Compare XGBoost, MLP, and QNN across feature sets\n",
    "3. **Statistical Significance**: Identify meaningful differences\n",
    "4. **Feature Stability**: Assess consistency of selected features\n",
    "\n",
    "### Important Notes:\n",
    "- Quantum-inspired methods are classical simulations, not quantum computing\n",
    "- Risk scores represent likelihood, NOT medical diagnosis\n",
    "- Results should be validated on independent datasets before clinical use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
